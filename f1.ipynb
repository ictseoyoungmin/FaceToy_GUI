{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# face mesh 모델 로드\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "# 첫 번째 이미지에서 face mesh 좌표값 추출\n",
    "img1 = cv2.imread('images.jpg')\n",
    "img1_h, img1_w, _ = img1.shape\n",
    "results1 = face_mesh.process(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "points1 = []\n",
    "if results1.multi_face_landmarks:\n",
    "    for landmark in results1.multi_face_landmarks[0].landmark:\n",
    "        points1.append([landmark.x * img1_w, landmark.y * img1_h])\n",
    "\n",
    "# 두 번째 이미지에서 face mesh 좌표값 추출\n",
    "img2 = cv2.imread('images2.jfif')\n",
    "img2_h, img2_w, _ = img2.shape\n",
    "results2 = face_mesh.process(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "points2 = []\n",
    "if results2.multi_face_landmarks:\n",
    "    for landmark in results2.multi_face_landmarks[0].landmark:\n",
    "        points2.append([landmark.x * img2_w, landmark.y * img2_h])\n",
    "\n",
    "# face mesh 좌표값 대응시키기\n",
    "M, _ = cv2.estimateAffinePartial2D(np.array(points2), np.array(points1))\n",
    "\n",
    "# 두 번째 이미지를 첫 번째 이미지의 얼굴 모양으로 변환\n",
    "result = cv2.warpAffine(img2, M, (img1_w, img1_h))\n",
    "\n",
    "# 결과 이미지 출력\n",
    "cv2.imshow(\"Face Transfer Result\", result)\n",
    "cv2.imshow(\"1\",test_m3(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)))\n",
    "cv2.imshow(\"2\",test_m3(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# 이미지 1에서 face mesh 추출\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5) as face_mesh:\n",
    "    img1 = cv2.imread('images.jpg')\n",
    "    img1 = cv2.resize(img1, (640, 480))\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(img1)\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_RGB2BGR)\n",
    "    if results.multi_face_landmarks:\n",
    "        face_landmarks1 = results.multi_face_landmarks[0]\n",
    "c=0\n",
    "a = []\n",
    "for i in face_landmarks1.landmark:\n",
    "    a.append(i.x)\n",
    "    c+=1\n",
    "print(len(a))\n",
    "# 이미지 2에서 face mesh 추출\n",
    "# with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5) as face_mesh:\n",
    "#     img2 = cv2.imread('images2.jfif')\n",
    "#     img2 = cv2.resize(img2, (640, 480))\n",
    "#     img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "#     results = face_mesh.process(img2)\n",
    "#     img2 = cv2.cvtColor(img2, cv2.COLOR_RGB2BGR)\n",
    "#     if results.multi_face_landmarks:\n",
    "#         face_landmarks2 = results.multi_face_landmarks[0]\n",
    "\n",
    "# # 이미지 1에서 face mesh 제거한 영역과 이미지 2에서 face mesh 영역을 합성\n",
    "# img1_face = img1.copy()\n",
    "# img2_face = img2.copy()\n",
    "\n",
    "# for landmark in face_landmarks1.landmark:\n",
    "#     x, y = int(landmark.x * img1.shape[1]), int(landmark.y * img1.shape[0])\n",
    "#     cv2.circle(img1_face, (x, y), 1, (0, 0, 255), -1)\n",
    "\n",
    "# for landmark in face_landmarks2.landmark:\n",
    "#     x, y = int(landmark.x * img2.shape[1]), int(landmark.y * img2.shape[0])\n",
    "#     cv2.circle(img2_face, (x, y), 1, (0, 0, 255), -1)\n",
    "\n",
    "# img2_face_mask = cv2.cvtColor(img2_face, cv2.COLOR_BGR2GRAY)\n",
    "# img2_face_mask = cv2.merge([img2_face_mask, img2_face_mask, img2_face_mask])\n",
    "# img1_bg = cv2.bitwise_and(img1, img2_face_mask)\n",
    "# img2_fg = cv2.bitwise_and(img2, img2_face_mask)\n",
    "# dst = cv2.add(img1_bg, img2_fg)\n",
    "\n",
    "# # 합성 결과 출력\n",
    "# cv2.imshow('Result', dst)\n",
    "# cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\201721360\\PythonWork\\FaceToy_GUI\\f1.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/201721360/PythonWork/FaceToy_GUI/f1.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m landmarks2_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([(lmk\u001b[39m.\u001b[39mx, lmk\u001b[39m.\u001b[39my, lmk\u001b[39m.\u001b[39mz) \u001b[39mfor\u001b[39;00m lmk \u001b[39min\u001b[39;00m landmarks2])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/201721360/PythonWork/FaceToy_GUI/f1.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# affine transformation matrix 계산\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/201721360/PythonWork/FaceToy_GUI/f1.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m _,transformation_matrix \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mestimateAffine3D(landmarks1_arr, landmarks2_arr, ransacThreshold\u001b[39m=\u001b[39m\u001b[39m3.0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/201721360/PythonWork/FaceToy_GUI/f1.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# 이미지 1에서 face mesh 추출 후, 이미지 2의 좌표로 변환\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/201721360/PythonWork/FaceToy_GUI/f1.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m img1_landmarks \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([landmarks1_arr, np\u001b[39m.\u001b[39mones((\u001b[39mlen\u001b[39m(landmarks1_arr), \u001b[39m1\u001b[39m))], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 이미지 파일 로드\n",
    "img1 = cv2.imread('images.jpg')\n",
    "img2 = cv2.imread('images2.jfif')\n",
    "\n",
    "# face mesh 모델 초기화\n",
    "with mp_face_mesh.FaceMesh() as face_mesh:\n",
    "\n",
    "    # 이미지 1에서 face mesh 좌표값 추출\n",
    "    results1 = face_mesh.process(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "    landmarks1 = results1.multi_face_landmarks[0].landmark\n",
    "    \n",
    "    # 이미지 2에서 face mesh 좌표값 추출\n",
    "    results2 = face_mesh.process(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "    landmarks2 = results2.multi_face_landmarks[0].landmark\n",
    "    \n",
    "    # 좌표값 배열 생성\n",
    "    landmarks1_arr = np.array([(lmk.x, lmk.y, lmk.z) for lmk in landmarks1])\n",
    "    landmarks2_arr = np.array([(lmk.x, lmk.y, lmk.z) for lmk in landmarks2])\n",
    "    \n",
    "    # affine transformation matrix 계산\n",
    "    _,transformation_matrix = cv2.estimateAffine3D(landmarks1_arr, landmarks2_arr, ransacThreshold=3.0)\n",
    "    \n",
    "    # 이미지 1에서 face mesh 추출 후, 이미지 2의 좌표로 변환\n",
    "    img1_landmarks = np.concatenate([landmarks1_arr, np.ones((len(landmarks1_arr), 1))], axis=1)\n",
    "    img2_landmarks = np.dot(transformation_matrix, img1_landmarks.T).T[:,:-1]\n",
    "    \n",
    "    # 이미지 1에서 face mesh 제거\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    mask = np.zeros_like(img1_gray)\n",
    "    points = cv2.convexHull(np.array([(lmk[0], lmk[1]) for lmk in img2_landmarks], dtype=np.int32))\n",
    "    cv2.fillConvexPoly(mask, points, (255, 255, 255))\n",
    "    img1_face = cv2.bitwise_and(img1, img1, mask=mask)\n",
    "    \n",
    "    # 이미지 2에서 face mesh 영역 추출\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(img2_gray, 1, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    img2_face = np.zeros_like(img2)\n",
    "    cv2.drawContours(img2_face, contours, -1, (255, 255, 255), -1)\n",
    "    \n",
    "    # 이미지 1에서 face mesh 제거한 영역과 이미지 2에서 face mesh 영역을 합성\n",
    "    img2_face_mask = cv2.cvtColor(img2_face, cv2.COLOR_BGR2GRAY)\n",
    "    img2_face_mask = cv2.merge([img2_face_mask, img2_face_mask, img2_face_mask])\n",
    "    img1_bg = cv2.bitwise_and(img1, img1_face)\n",
    "    img2_fg = cv2.bitwise_and(img2, img2_face_mask)\n",
    "    dst = cv2.add(img1_face, img2_fg)\n",
    "    \n",
    "    # 합성 결과 출력\n",
    "    cv2.imshow('Result', dst)\n",
    "    cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\201721360\\PythonWork\\FaceToy_GUI\\f1.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/201721360/PythonWork/FaceToy_GUI/f1.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m landmarks2_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([(lmk\u001b[39m.\u001b[39mx, lmk\u001b[39m.\u001b[39my, lmk\u001b[39m.\u001b[39mz) \u001b[39mfor\u001b[39;00m lmk \u001b[39min\u001b[39;00m landmarks2])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/201721360/PythonWork/FaceToy_GUI/f1.ipynb#W4sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# affine transformation matrix 계산\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/201721360/PythonWork/FaceToy_GUI/f1.ipynb#W4sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m _, transformation_matrix \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mestimateAffine3D(landmarks1_arr, landmarks2_arr, ransacThreshold\u001b[39m=\u001b[39m\u001b[39m3.0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/201721360/PythonWork/FaceToy_GUI/f1.ipynb#W4sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# 이미지 1에서 face mesh 추출 후, 이미지 2의 좌표로 변환\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/201721360/PythonWork/FaceToy_GUI/f1.ipynb#W4sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m img1_landmarks \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([landmarks1_arr, np\u001b[39m.\u001b[39mones((\u001b[39mlen\u001b[39m(landmarks1_arr), \u001b[39m1\u001b[39m))], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('images.jpg')\n",
    "img2 = cv2.imread('images2.jfif')\n",
    "\n",
    "# face mesh 모델 로드\n",
    "with mp_face_mesh.FaceMesh() as face_mesh:\n",
    "    # 이미지 1에서 face mesh 추출\n",
    "    results1 = face_mesh.process(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "    # 좌표 추출\n",
    "    landmarks1 = results1.multi_face_landmarks[0].landmark\n",
    "    # 좌표를 numpy 배열로 변환\n",
    "    landmarks1_arr = np.array([(lmk.x, lmk.y, lmk.z) for lmk in landmarks1])\n",
    "\n",
    "    # 이미지 2에서 face mesh 추출\n",
    "    results2 = face_mesh.process(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "    # 좌표 추출\n",
    "    landmarks2 = results2.multi_face_landmarks[0].landmark\n",
    "    # 좌표를 numpy 배열로 변환\n",
    "    landmarks2_arr = np.array([(lmk.x, lmk.y, lmk.z) for lmk in landmarks2])\n",
    "\n",
    "    # affine transformation matrix 계산\n",
    "    _, transformation_matrix = cv2.estimateAffine3D(landmarks1_arr, landmarks2_arr, ransacThreshold=3.0)\n",
    "\n",
    "    # 이미지 1에서 face mesh 추출 후, 이미지 2의 좌표로 변환\n",
    "    img1_landmarks = np.concatenate([landmarks1_arr, np.ones((len(landmarks1_arr), 1))], axis=1)\n",
    "    img2_landmarks = np.concatenate([landmarks2_arr, np.ones((len(landmarks2_arr), 1))], axis=1)\n",
    "\n",
    "    img1_landmarks_trans = (transformation_matrix @ img1_landmarks.T).T[:, :3]\n",
    "\n",
    "    # 변환된 좌표를 이미지 2에 그리기\n",
    "    img2_copy = np.copy(img2)\n",
    "    for landmark in img1_landmarks_trans.astype(np.int32):\n",
    "        cv2.circle(img2_copy, tuple(landmark[:2]), 1, (0, 255, 0), -1)\n",
    "\n",
    "    # 결과 이미지 출력\n",
    "    cv2.imshow('result', img2_copy)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
